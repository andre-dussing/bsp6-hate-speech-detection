modelroberta-basedataset: /content/drive/MyDrive/BSP6/init_dataset_gold_preprocessed
structure of the model: 
RobertaForSequenceClassification(
  (roberta): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (classifier): RobertaClassificationHead(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (out_proj): Linear(in_features=768, out_features=3, bias=True)
  )
)
Tokenizer max length train:225Tokenizer max length val:225Tokenizer max length test:225
TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=50,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/runs/Jun11_06-49-26_788e6ddfd356,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
optim=adamw_hf,
optim_args=None,
output_dir=./results,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./results,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
Confusion Matrix
[[  0 202   0]
 [  0 356   0]
 [  0 155   0]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.00      0.00      0.00       202
     Neutral       0.50      1.00      0.67       356
     Counter       0.00      0.00      0.00       155

    accuracy                           0.50       713
   macro avg       0.17      0.33      0.22       713
weighted avg       0.25      0.50      0.33       713
Confusion Matrix
[[ 42  62  98]
 [ 35 225  96]
 [ 24  55  76]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.42      0.21      0.28       202
     Neutral       0.66      0.63      0.64       356
     Counter       0.28      0.49      0.36       155

    accuracy                           0.48       713
   macro avg       0.45      0.44      0.43       713
weighted avg       0.51      0.48      0.48       713
Confusion Matrix
[[ 65 125  12]
 [ 18 326  12]
 [ 31 111  13]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.32      0.41       202
     Neutral       0.58      0.92      0.71       356
     Counter       0.35      0.08      0.14       155

    accuracy                           0.57       713
   macro avg       0.50      0.44      0.42       713
weighted avg       0.53      0.57      0.50       713
Confusion Matrix
[[115  65  22]
 [ 77 250  29]
 [ 59  70  26]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.46      0.57      0.51       202
     Neutral       0.65      0.70      0.67       356
     Counter       0.34      0.17      0.22       155

    accuracy                           0.55       713
   macro avg       0.48      0.48      0.47       713
weighted avg       0.53      0.55      0.53       713
Confusion Matrix
[[139  41  22]
 [ 94 219  43]
 [ 72  53  30]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.46      0.69      0.55       202
     Neutral       0.70      0.62      0.65       356
     Counter       0.32      0.19      0.24       155

    accuracy                           0.54       713
   macro avg       0.49      0.50      0.48       713
weighted avg       0.55      0.54      0.53       713
Confusion Matrix
[[118  64  20]
 [ 56 270  30]
 [ 49  69  37]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.53      0.58      0.56       202
     Neutral       0.67      0.76      0.71       356
     Counter       0.43      0.24      0.31       155

    accuracy                           0.60       713
   macro avg       0.54      0.53      0.52       713
weighted avg       0.58      0.60      0.58       713
Confusion Matrix
[[ 82  77  43]
 [ 35 285  36]
 [ 23  91  41]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.41      0.48       202
     Neutral       0.63      0.80      0.70       356
     Counter       0.34      0.26      0.30       155

    accuracy                           0.57       713
   macro avg       0.52      0.49      0.49       713
weighted avg       0.55      0.57      0.55       713
Confusion Matrix
[[ 88  48  66]
 [ 41 232  83]
 [ 25  53  77]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.44      0.49       202
     Neutral       0.70      0.65      0.67       356
     Counter       0.34      0.50      0.40       155

    accuracy                           0.56       713
   macro avg       0.54      0.53      0.52       713
weighted avg       0.58      0.56      0.56       713
Confusion Matrix
[[120  60  22]
 [ 68 259  29]
 [ 47  72  36]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.51      0.59      0.55       202
     Neutral       0.66      0.73      0.69       356
     Counter       0.41      0.23      0.30       155

    accuracy                           0.58       713
   macro avg       0.53      0.52      0.51       713
weighted avg       0.57      0.58      0.57       713
Confusion Matrix
[[122  51  29]
 [ 69 244  43]
 [ 44  59  52]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.52      0.60      0.56       202
     Neutral       0.69      0.69      0.69       356
     Counter       0.42      0.34      0.37       155

    accuracy                           0.59       713
   macro avg       0.54      0.54      0.54       713
weighted avg       0.58      0.59      0.58       713
[{'loss': 1.0524, 'learning_rate': 1.807692307692308e-05, 'epoch': 0.48, 'step': 50}, {'eval_loss': 1.0321147441864014, 'eval_accuracy': 0.4992987377279102, 'eval_precision': 0.24929922949668448, 'eval_recall': 0.4992987377279102, 'eval_f1': 0.3325544445858485, 'eval_runtime': 9.7141, 'eval_samples_per_second': 73.398, 'eval_steps_per_second': 2.368, 'epoch': 0.48, 'step': 50}, {'loss': 1.0229, 'learning_rate': 1.6153846153846154e-05, 'epoch': 0.96, 'step': 100}, {'eval_loss': 1.0081955194473267, 'eval_accuracy': 0.48106591865357645, 'eval_precision': 0.5074896997831965, 'eval_recall': 0.48106591865357645, 'eval_f1': 0.4781882021044251, 'eval_runtime': 9.9186, 'eval_samples_per_second': 71.885, 'eval_steps_per_second': 2.319, 'epoch': 0.96, 'step': 100}, {'loss': 0.9317, 'learning_rate': 1.4230769230769232e-05, 'epoch': 1.44, 'step': 150}, {'eval_loss': 0.9492923021316528, 'eval_accuracy': 0.5666199158485273, 'eval_precision': 0.5275459132317567, 'eval_recall': 0.5666199158485273, 'eval_f1': 0.5006117322023248, 'eval_runtime': 9.9627, 'eval_samples_per_second': 71.567, 'eval_steps_per_second': 2.309, 'epoch': 1.44, 'step': 150}, {'loss': 0.9289, 'learning_rate': 1.230769230769231e-05, 'epoch': 1.92, 'step': 200}, {'eval_loss': 0.9394580721855164, 'eval_accuracy': 0.5483870967741935, 'eval_precision': 0.5274281827535852, 'eval_recall': 0.5483870967741935, 'eval_f1': 0.5294782750891467, 'eval_runtime': 9.9228, 'eval_samples_per_second': 71.855, 'eval_steps_per_second': 2.318, 'epoch': 1.92, 'step': 200}, {'loss': 0.8203, 'learning_rate': 1.0384615384615386e-05, 'epoch': 2.4, 'step': 250}, {'eval_loss': 1.013324499130249, 'eval_accuracy': 0.544179523141655, 'eval_precision': 0.5471145116343982, 'eval_recall': 0.544179523141655, 'eval_f1': 0.5344145503600788, 'eval_runtime': 9.9266, 'eval_samples_per_second': 71.827, 'eval_steps_per_second': 2.317, 'epoch': 2.4, 'step': 250}, {'loss': 0.7726, 'learning_rate': 8.461538461538462e-06, 'epoch': 2.88, 'step': 300}, {'eval_loss': 0.9263197183609009, 'eval_accuracy': 0.5960729312762973, 'eval_precision': 0.5768844303782166, 'eval_recall': 0.5960729312762973, 'eval_f1': 0.579027683577348, 'eval_runtime': 9.9245, 'eval_samples_per_second': 71.842, 'eval_steps_per_second': 2.317, 'epoch': 2.88, 'step': 300}, {'loss': 0.7215, 'learning_rate': 6.538461538461539e-06, 'epoch': 3.37, 'step': 350}, {'eval_loss': 1.0083850622177124, 'eval_accuracy': 0.5722300140252454, 'eval_precision': 0.5543423968883504, 'eval_recall': 0.5722300140252454, 'eval_f1': 0.5524710544685957, 'eval_runtime': 9.8989, 'eval_samples_per_second': 72.028, 'eval_steps_per_second': 2.323, 'epoch': 3.37, 'step': 350}, {'loss': 0.665, 'learning_rate': 4.615384615384616e-06, 'epoch': 3.85, 'step': 400}, {'eval_loss': 1.042717456817627, 'eval_accuracy': 0.5568022440392707, 'eval_precision': 0.5838181345944878, 'eval_recall': 0.5568022440392707, 'eval_f1': 0.5641804270742768, 'eval_runtime': 9.9023, 'eval_samples_per_second': 72.004, 'eval_steps_per_second': 2.323, 'epoch': 3.85, 'step': 400}, {'loss': 0.6047, 'learning_rate': 2.6923076923076923e-06, 'epoch': 4.33, 'step': 450}, {'eval_loss': 1.0404051542282104, 'eval_accuracy': 0.5820476858345021, 'eval_precision': 0.5653614642106439, 'eval_recall': 0.5820476858345021, 'eval_f1': 0.5665059047484718, 'eval_runtime': 9.9005, 'eval_samples_per_second': 72.017, 'eval_steps_per_second': 2.323, 'epoch': 4.33, 'step': 450}, {'loss': 0.5833, 'learning_rate': 7.692307692307694e-07, 'epoch': 4.81, 'step': 500}, {'eval_loss': 1.0508861541748047, 'eval_accuracy': 0.5862552594670407, 'eval_precision': 0.5823935710797045, 'eval_recall': 0.5862552594670407, 'eval_f1': 0.5824015246509548, 'eval_runtime': 9.9063, 'eval_samples_per_second': 71.975, 'eval_steps_per_second': 2.322, 'epoch': 4.81, 'step': 500}, {'train_runtime': 753.61, 'train_samples_per_second': 22.06, 'train_steps_per_second': 0.69, 'total_flos': 1922282476931250.0, 'train_loss': 0.800556624852694, 'epoch': 5.0, 'step': 520}]Confusion Matrix
[[112  44  28]
 [ 63 258  40]
 [ 38  55  75]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.53      0.61      0.56       184
     Neutral       0.72      0.71      0.72       361
     Counter       0.52      0.45      0.48       168

    accuracy                           0.62       713
   macro avg       0.59      0.59      0.59       713
weighted avg       0.63      0.62      0.62       713
{'eval_loss': 0.9945931434631348, 'eval_accuracy': 0.6241234221598878, 'eval_precision': 0.6251806705797045, 'eval_recall': 0.6241234221598878, 'eval_f1': 0.6231204833247315, 'eval_runtime': 10.1804, 'eval_samples_per_second': 70.037, 'eval_steps_per_second': 2.259, 'epoch': 5.0}