modelbert-base-caseddataset: /content/drive/MyDrive/BSP6/init_dataset_gold_silver_balance
structure of the model: 
BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(28996, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=3, bias=True)
)
Tokenizer max length train:225Tokenizer max length val:225Tokenizer max length test:225
TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=50,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/runs/Jun11_11-47-22_c7dc168e2572,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
optim=adamw_hf,
optim_args=None,
output_dir=./results,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./results,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
Confusion Matrix
[[ 99 232   0]
 [ 76 280   0]
 [ 59 190   0]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.42      0.30      0.35       331
     Neutral       0.40      0.79      0.53       356
     Counter       0.00      0.00      0.00       249

    accuracy                           0.40       936
   macro avg       0.27      0.36      0.29       936
weighted avg       0.30      0.40      0.33       936
Confusion Matrix
[[217  83  31]
 [127 192  37]
 [122  81  46]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.47      0.66      0.54       331
     Neutral       0.54      0.54      0.54       356
     Counter       0.40      0.18      0.25       249

    accuracy                           0.49       936
   macro avg       0.47      0.46      0.45       936
weighted avg       0.48      0.49      0.47       936
Confusion Matrix
[[167  97  67]
 [ 72 234  50]
 [ 61 105  83]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.56      0.50      0.53       331
     Neutral       0.54      0.66      0.59       356
     Counter       0.41      0.33      0.37       249

    accuracy                           0.52       936
   macro avg       0.50      0.50      0.50       936
weighted avg       0.51      0.52      0.51       936
Confusion Matrix
[[131  92 108]
 [ 63 207  86]
 [ 46  90 113]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.40      0.46       331
     Neutral       0.53      0.58      0.56       356
     Counter       0.37      0.45      0.41       249

    accuracy                           0.48       936
   macro avg       0.48      0.48      0.47       936
weighted avg       0.49      0.48      0.48       936
Confusion Matrix
[[204  63  64]
 [ 90 204  62]
 [ 75  79  95]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.62      0.58       331
     Neutral       0.59      0.57      0.58       356
     Counter       0.43      0.38      0.40       249

    accuracy                           0.54       936
   macro avg       0.52      0.52      0.52       936
weighted avg       0.53      0.54      0.53       936
Confusion Matrix
[[202  60  69]
 [ 82 184  90]
 [ 73  64 112]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.61      0.59       331
     Neutral       0.60      0.52      0.55       356
     Counter       0.41      0.45      0.43       249

    accuracy                           0.53       936
   macro avg       0.53      0.53      0.52       936
weighted avg       0.54      0.53      0.53       936
Confusion Matrix
[[114  70 147]
 [ 44 189 123]
 [ 34  69 146]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.34      0.44       331
     Neutral       0.58      0.53      0.55       356
     Counter       0.35      0.59      0.44       249

    accuracy                           0.48       936
   macro avg       0.51      0.49      0.48       936
weighted avg       0.52      0.48      0.48       936
Confusion Matrix
[[174  60  97]
 [ 75 186  95]
 [ 58  72 119]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.53      0.55       331
     Neutral       0.58      0.52      0.55       356
     Counter       0.38      0.48      0.43       249

    accuracy                           0.51       936
   macro avg       0.51      0.51      0.51       936
weighted avg       0.52      0.51      0.52       936
Confusion Matrix
[[167  79  85]
 [ 72 213  71]
 [ 55  86 108]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.50      0.53       331
     Neutral       0.56      0.60      0.58       356
     Counter       0.41      0.43      0.42       249

    accuracy                           0.52       936
   macro avg       0.51      0.51      0.51       936
weighted avg       0.52      0.52      0.52       936
Confusion Matrix
[[182  82  67]
 [ 68 239  49]
 [ 63  97  89]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.58      0.55      0.57       331
     Neutral       0.57      0.67      0.62       356
     Counter       0.43      0.36      0.39       249

    accuracy                           0.54       936
   macro avg       0.53      0.53      0.52       936
weighted avg       0.54      0.54      0.54       936
Confusion Matrix
[[143  70 118]
 [ 56 190 110]
 [ 45  73 131]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.43      0.50       331
     Neutral       0.57      0.53      0.55       356
     Counter       0.36      0.53      0.43       249

    accuracy                           0.50       936
   macro avg       0.51      0.50      0.49       936
weighted avg       0.52      0.50      0.50       936
Confusion Matrix
[[169  73  89]
 [ 71 199  86]
 [ 55  83 111]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.51      0.54       331
     Neutral       0.56      0.56      0.56       356
     Counter       0.39      0.45      0.41       249

    accuracy                           0.51       936
   macro avg       0.51      0.51      0.50       936
weighted avg       0.52      0.51      0.51       936
Confusion Matrix
[[168  71  92]
 [ 65 195  96]
 [ 53  81 115]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.51      0.54       331
     Neutral       0.56      0.55      0.55       356
     Counter       0.38      0.46      0.42       249

    accuracy                           0.51       936
   macro avg       0.51      0.51      0.51       936
weighted avg       0.52      0.51      0.51       936
[{'loss': 1.1096, 'learning_rate': 1.849624060150376e-05, 'epoch': 0.38, 'step': 50}, {'eval_loss': 1.0806329250335693, 'eval_accuracy': 0.4049145299145299, 'eval_precision': 0.3013170550563713, 'eval_recall': 0.4049145299145299, 'eval_f1': 0.3252430150292205, 'eval_runtime': 13.2959, 'eval_samples_per_second': 70.397, 'eval_steps_per_second': 2.256, 'epoch': 0.38, 'step': 50}, {'loss': 1.0618, 'learning_rate': 1.699248120300752e-05, 'epoch': 0.75, 'step': 100}, {'eval_loss': 1.0172221660614014, 'eval_accuracy': 0.4861111111111111, 'eval_precision': 0.47714623647817683, 'eval_recall': 0.4861111111111111, 'eval_f1': 0.46511843035739464, 'eval_runtime': 13.406, 'eval_samples_per_second': 69.82, 'eval_steps_per_second': 2.238, 'epoch': 0.75, 'step': 100}, {'loss': 1.0035, 'learning_rate': 1.548872180451128e-05, 'epoch': 1.13, 'step': 150}, {'eval_loss': 0.9903926253318787, 'eval_accuracy': 0.5170940170940171, 'eval_precision': 0.5113844944980266, 'eval_recall': 0.5170940170940171, 'eval_f1': 0.5102841669053254, 'eval_runtime': 13.2428, 'eval_samples_per_second': 70.68, 'eval_steps_per_second': 2.265, 'epoch': 1.13, 'step': 150}, {'loss': 0.9069, 'learning_rate': 1.3984962406015038e-05, 'epoch': 1.5, 'step': 200}, {'eval_loss': 1.0165228843688965, 'eval_accuracy': 0.48183760683760685, 'eval_precision': 0.4933353502353899, 'eval_recall': 0.48183760683760685, 'eval_f1': 0.48175268243065267, 'eval_runtime': 13.2886, 'eval_samples_per_second': 70.436, 'eval_steps_per_second': 2.258, 'epoch': 1.5, 'step': 200}, {'loss': 0.9145, 'learning_rate': 1.2481203007518798e-05, 'epoch': 1.88, 'step': 250}, {'eval_loss': 0.9746006727218628, 'eval_accuracy': 0.5373931623931624, 'eval_precision': 0.5341068619347727, 'eval_recall': 0.5373931623931624, 'eval_f1': 0.5347128970724169, 'eval_runtime': 13.3352, 'eval_samples_per_second': 70.19, 'eval_steps_per_second': 2.25, 'epoch': 1.88, 'step': 250}, {'loss': 0.7676, 'learning_rate': 1.0977443609022558e-05, 'epoch': 2.26, 'step': 300}, {'eval_loss': 1.0456236600875854, 'eval_accuracy': 0.532051282051282, 'eval_precision': 0.5372559713236944, 'eval_recall': 0.532051282051282, 'eval_f1': 0.5330438272976314, 'eval_runtime': 13.3118, 'eval_samples_per_second': 70.314, 'eval_steps_per_second': 2.254, 'epoch': 2.26, 'step': 300}, {'loss': 0.7211, 'learning_rate': 9.473684210526315e-06, 'epoch': 2.63, 'step': 350}, {'eval_loss': 1.101667881011963, 'eval_accuracy': 0.4797008547008547, 'eval_precision': 0.5224944651905838, 'eval_recall': 0.4797008547008547, 'eval_f1': 0.4811650209506706, 'eval_runtime': 13.3192, 'eval_samples_per_second': 70.274, 'eval_steps_per_second': 2.252, 'epoch': 2.63, 'step': 350}, {'loss': 0.7171, 'learning_rate': 7.969924812030075e-06, 'epoch': 3.01, 'step': 400}, {'eval_loss': 1.0650393962860107, 'eval_accuracy': 0.5117521367521367, 'eval_precision': 0.5246854148383777, 'eval_recall': 0.5117521367521367, 'eval_f1': 0.5158729716129568, 'eval_runtime': 13.277, 'eval_samples_per_second': 70.498, 'eval_steps_per_second': 2.26, 'epoch': 3.01, 'step': 400}, {'loss': 0.5426, 'learning_rate': 6.466165413533835e-06, 'epoch': 3.38, 'step': 450}, {'eval_loss': 1.129928708076477, 'eval_accuracy': 0.5213675213675214, 'eval_precision': 0.5240211728306966, 'eval_recall': 0.5213675213675214, 'eval_f1': 0.5217353729464442, 'eval_runtime': 13.2345, 'eval_samples_per_second': 70.724, 'eval_steps_per_second': 2.267, 'epoch': 3.38, 'step': 450}, {'loss': 0.5379, 'learning_rate': 4.962406015037594e-06, 'epoch': 3.76, 'step': 500}, {'eval_loss': 1.1423691511154175, 'eval_accuracy': 0.5448717948717948, 'eval_precision': 0.5385888161676938, 'eval_recall': 0.5448717948717948, 'eval_f1': 0.53906816703008, 'eval_runtime': 13.2428, 'eval_samples_per_second': 70.68, 'eval_steps_per_second': 2.265, 'epoch': 3.76, 'step': 500}, {'loss': 0.4925, 'learning_rate': 3.4586466165413535e-06, 'epoch': 4.14, 'step': 550}, {'eval_loss': 1.211509346961975, 'eval_accuracy': 0.49572649572649574, 'eval_precision': 0.5213371284990803, 'eval_recall': 0.49572649572649574, 'eval_f1': 0.5002974244054731, 'eval_runtime': 13.1925, 'eval_samples_per_second': 70.95, 'eval_steps_per_second': 2.274, 'epoch': 4.14, 'step': 550}, {'loss': 0.435, 'learning_rate': 1.9548872180451127e-06, 'epoch': 4.51, 'step': 600}, {'eval_loss': 1.2149990797042847, 'eval_accuracy': 0.5117521367521367, 'eval_precision': 0.5190428977924157, 'eval_recall': 0.5117521367521367, 'eval_f1': 0.5142330147528377, 'eval_runtime': 13.3087, 'eval_samples_per_second': 70.33, 'eval_steps_per_second': 2.254, 'epoch': 4.51, 'step': 600}, {'loss': 0.4305, 'learning_rate': 4.511278195488722e-07, 'epoch': 4.89, 'step': 650}, {'eval_loss': 1.2241729497909546, 'eval_accuracy': 0.5106837606837606, 'eval_precision': 0.5224317882651965, 'eval_recall': 0.5106837606837606, 'eval_f1': 0.5144223078172366, 'eval_runtime': 13.2437, 'eval_samples_per_second': 70.675, 'eval_steps_per_second': 2.265, 'epoch': 4.89, 'step': 650}, {'train_runtime': 969.9664, 'train_samples_per_second': 21.836, 'train_steps_per_second': 0.686, 'total_flos': 2448958969107000.0, 'train_loss': 0.7333222833791173, 'epoch': 5.0, 'step': 665}]Confusion Matrix
[[102  51  31]
 [ 62 241  58]
 [ 31  68  69]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.52      0.55      0.54       184
     Neutral       0.67      0.67      0.67       361
     Counter       0.44      0.41      0.42       168

    accuracy                           0.58       713
   macro avg       0.54      0.54      0.54       713
weighted avg       0.58      0.58      0.58       713
{'eval_loss': 1.0462079048156738, 'eval_accuracy': 0.5778401122019635, 'eval_precision': 0.576834062970818, 'eval_recall': 0.5778401122019635, 'eval_f1': 0.5771253860149006, 'eval_runtime': 10.0881, 'eval_samples_per_second': 70.677, 'eval_steps_per_second': 2.28, 'epoch': 5.0}