modelGroNLP/hateBERTdataset: /content/drive/MyDrive/BSP6/init_dataset_gold_silver_balance
structure of the model: 
BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=3, bias=True)
)
Tokenizer max length train:225Tokenizer max length val:225Tokenizer max length test:225
TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=50,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/runs/Jun11_12-29-54_c7dc168e2572,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
optim=adamw_hf,
optim_args=None,
output_dir=./results,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./results,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
Confusion Matrix
[[134 158  39]
 [ 73 257  26]
 [103 115  31]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.43      0.40      0.42       331
     Neutral       0.48      0.72      0.58       356
     Counter       0.32      0.12      0.18       249

    accuracy                           0.45       936
   macro avg       0.41      0.42      0.39       936
weighted avg       0.42      0.45      0.42       936
Confusion Matrix
[[193 114  24]
 [103 232  21]
 [135  83  31]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.45      0.58      0.51       331
     Neutral       0.54      0.65      0.59       356
     Counter       0.41      0.12      0.19       249

    accuracy                           0.49       936
   macro avg       0.47      0.45      0.43       936
weighted avg       0.47      0.49      0.45       936
Confusion Matrix
[[169  71  91]
 [ 79 203  74]
 [ 92  57 100]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.50      0.51      0.50       331
     Neutral       0.61      0.57      0.59       356
     Counter       0.38      0.40      0.39       249

    accuracy                           0.50       936
   macro avg       0.50      0.49      0.49       936
weighted avg       0.51      0.50      0.51       936
Confusion Matrix
[[130 100 101]
 [ 56 228  72]
 [ 57  77 115]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.53      0.39      0.45       331
     Neutral       0.56      0.64      0.60       356
     Counter       0.40      0.46      0.43       249

    accuracy                           0.51       936
   macro avg       0.50      0.50      0.49       936
weighted avg       0.51      0.51      0.50       936
Confusion Matrix
[[147  82 102]
 [ 70 227  59]
 [ 60  79 110]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.53      0.44      0.48       331
     Neutral       0.59      0.64      0.61       356
     Counter       0.41      0.44      0.42       249

    accuracy                           0.52       936
   macro avg       0.51      0.51      0.51       936
weighted avg       0.52      0.52      0.52       936
Confusion Matrix
[[184  73  74]
 [ 77 210  69]
 [ 88  65  96]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.53      0.56      0.54       331
     Neutral       0.60      0.59      0.60       356
     Counter       0.40      0.39      0.39       249

    accuracy                           0.52       936
   macro avg       0.51      0.51      0.51       936
weighted avg       0.52      0.52      0.52       936
Confusion Matrix
[[136  88 107]
 [ 46 225  85]
 [ 45  76 128]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.60      0.41      0.49       331
     Neutral       0.58      0.63      0.60       356
     Counter       0.40      0.51      0.45       249

    accuracy                           0.52       936
   macro avg       0.53      0.52      0.51       936
weighted avg       0.54      0.52      0.52       936
Confusion Matrix
[[170  70  91]
 [ 67 206  83]
 [ 72  70 107]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.51      0.53       331
     Neutral       0.60      0.58      0.59       356
     Counter       0.38      0.43      0.40       249

    accuracy                           0.52       936
   macro avg       0.51      0.51      0.51       936
weighted avg       0.52      0.52      0.52       936
Confusion Matrix
[[148 104  79]
 [ 52 244  60]
 [ 64  87  98]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.56      0.45      0.50       331
     Neutral       0.56      0.69      0.62       356
     Counter       0.41      0.39      0.40       249

    accuracy                           0.52       936
   macro avg       0.51      0.51      0.51       936
weighted avg       0.52      0.52      0.52       936
Confusion Matrix
[[178  74  79]
 [ 69 216  71]
 [ 77  70 102]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.54      0.54       331
     Neutral       0.60      0.61      0.60       356
     Counter       0.40      0.41      0.41       249

    accuracy                           0.53       936
   macro avg       0.52      0.52      0.52       936
weighted avg       0.53      0.53      0.53       936
Confusion Matrix
[[150  88  93]
 [ 54 233  69]
 [ 50  81 118]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.45      0.51       331
     Neutral       0.58      0.65      0.61       356
     Counter       0.42      0.47      0.45       249

    accuracy                           0.54       936
   macro avg       0.53      0.53      0.52       936
weighted avg       0.54      0.54      0.53       936
Confusion Matrix
[[188  67  76]
 [ 77 208  71]
 [ 79  67 103]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.57      0.56       331
     Neutral       0.61      0.58      0.60       356
     Counter       0.41      0.41      0.41       249

    accuracy                           0.53       936
   macro avg       0.52      0.52      0.52       936
weighted avg       0.53      0.53      0.53       936
Confusion Matrix
[[178  73  80]
 [ 69 215  72]
 [ 73  70 106]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.56      0.54      0.55       331
     Neutral       0.60      0.60      0.60       356
     Counter       0.41      0.43      0.42       249

    accuracy                           0.53       936
   macro avg       0.52      0.52      0.52       936
weighted avg       0.53      0.53      0.53       936
[{'loss': 1.0832, 'learning_rate': 1.849624060150376e-05, 'epoch': 0.38, 'step': 50}, {'eval_loss': 1.0601004362106323, 'eval_accuracy': 0.45085470085470086, 'eval_precision': 0.42319453466792556, 'eval_recall': 0.45085470085470086, 'eval_f1': 0.416309891444305, 'eval_runtime': 13.193, 'eval_samples_per_second': 70.947, 'eval_steps_per_second': 2.274, 'epoch': 0.38, 'step': 50}, {'loss': 1.0309, 'learning_rate': 1.699248120300752e-05, 'epoch': 0.75, 'step': 100}, {'eval_loss': 1.0141935348510742, 'eval_accuracy': 0.48717948717948717, 'eval_precision': 0.4725516577235464, 'eval_recall': 0.48717948717948717, 'eval_f1': 0.4546997138664995, 'eval_runtime': 13.2645, 'eval_samples_per_second': 70.564, 'eval_steps_per_second': 2.262, 'epoch': 0.75, 'step': 100}, {'loss': 0.9853, 'learning_rate': 1.548872180451128e-05, 'epoch': 1.13, 'step': 150}, {'eval_loss': 1.001732349395752, 'eval_accuracy': 0.5042735042735043, 'eval_precision': 0.5094242104948361, 'eval_recall': 0.5042735042735043, 'eval_f1': 0.5064183591841277, 'eval_runtime': 13.1092, 'eval_samples_per_second': 71.4, 'eval_steps_per_second': 2.288, 'epoch': 1.13, 'step': 150}, {'loss': 0.9099, 'learning_rate': 1.3984962406015038e-05, 'epoch': 1.5, 'step': 200}, {'eval_loss': 0.9950642585754395, 'eval_accuracy': 0.5053418803418803, 'eval_precision': 0.509530007957863, 'eval_recall': 0.5053418803418803, 'eval_f1': 0.5020274305236703, 'eval_runtime': 13.2523, 'eval_samples_per_second': 70.629, 'eval_steps_per_second': 2.264, 'epoch': 1.5, 'step': 200}, {'loss': 0.8941, 'learning_rate': 1.2481203007518798e-05, 'epoch': 1.88, 'step': 250}, {'eval_loss': 0.9859771132469177, 'eval_accuracy': 0.5170940170940171, 'eval_precision': 0.5181682702219682, 'eval_recall': 0.5170940170940171, 'eval_f1': 0.515639566280524, 'eval_runtime': 13.1844, 'eval_samples_per_second': 70.993, 'eval_steps_per_second': 2.275, 'epoch': 1.88, 'step': 250}, {'loss': 0.7816, 'learning_rate': 1.0977443609022558e-05, 'epoch': 2.26, 'step': 300}, {'eval_loss': 1.0073270797729492, 'eval_accuracy': 0.5235042735042735, 'eval_precision': 0.5228144778438731, 'eval_recall': 0.5235042735042735, 'eval_f1': 0.5229519108075038, 'eval_runtime': 13.1589, 'eval_samples_per_second': 71.13, 'eval_steps_per_second': 2.28, 'epoch': 2.26, 'step': 300}, {'loss': 0.7437, 'learning_rate': 9.473684210526315e-06, 'epoch': 2.63, 'step': 350}, {'eval_loss': 1.0376898050308228, 'eval_accuracy': 0.5224358974358975, 'eval_precision': 0.5382702632960269, 'eval_recall': 0.5224358974358975, 'eval_f1': 0.5218048576984878, 'eval_runtime': 13.129, 'eval_samples_per_second': 71.293, 'eval_steps_per_second': 2.285, 'epoch': 2.63, 'step': 350}, {'loss': 0.749, 'learning_rate': 7.969924812030075e-06, 'epoch': 3.01, 'step': 400}, {'eval_loss': 1.0239522457122803, 'eval_accuracy': 0.5160256410256411, 'eval_precision': 0.5222994270461546, 'eval_recall': 0.5160256410256411, 'eval_f1': 0.518501971769212, 'eval_runtime': 13.1305, 'eval_samples_per_second': 71.284, 'eval_steps_per_second': 2.285, 'epoch': 3.01, 'step': 400}, {'loss': 0.629, 'learning_rate': 6.466165413533835e-06, 'epoch': 3.38, 'step': 450}, {'eval_loss': 1.0510051250457764, 'eval_accuracy': 0.5235042735042735, 'eval_precision': 0.5215918671996804, 'eval_recall': 0.5235042735042735, 'eval_f1': 0.517859130698701, 'eval_runtime': 13.1473, 'eval_samples_per_second': 71.193, 'eval_steps_per_second': 2.282, 'epoch': 3.38, 'step': 450}, {'loss': 0.613, 'learning_rate': 4.962406015037594e-06, 'epoch': 3.76, 'step': 500}, {'eval_loss': 1.0723414421081543, 'eval_accuracy': 0.5299145299145299, 'eval_precision': 0.5301617449765598, 'eval_recall': 0.5299145299145299, 'eval_f1': 0.5300051364557773, 'eval_runtime': 13.1422, 'eval_samples_per_second': 71.221, 'eval_steps_per_second': 2.283, 'epoch': 3.76, 'step': 500}, {'loss': 0.6011, 'learning_rate': 3.4586466165413535e-06, 'epoch': 4.14, 'step': 550}, {'eval_loss': 1.0949053764343262, 'eval_accuracy': 0.5352564102564102, 'eval_precision': 0.5413957945387902, 'eval_recall': 0.5352564102564102, 'eval_f1': 0.5338555707451991, 'eval_runtime': 13.0452, 'eval_samples_per_second': 71.75, 'eval_steps_per_second': 2.3, 'epoch': 4.14, 'step': 550}, {'loss': 0.5452, 'learning_rate': 1.9548872180451127e-06, 'epoch': 4.51, 'step': 600}, {'eval_loss': 1.0963969230651855, 'eval_accuracy': 0.5331196581196581, 'eval_precision': 0.5341858640173613, 'eval_recall': 0.5331196581196581, 'eval_f1': 0.5334879980816042, 'eval_runtime': 13.2011, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 2.273, 'epoch': 4.51, 'step': 600}, {'loss': 0.5584, 'learning_rate': 4.511278195488722e-07, 'epoch': 4.89, 'step': 650}, {'eval_loss': 1.1002085208892822, 'eval_accuracy': 0.5331196581196581, 'eval_precision': 0.5344230323322218, 'eval_recall': 0.5331196581196581, 'eval_f1': 0.533679255118012, 'eval_runtime': 13.1566, 'eval_samples_per_second': 71.143, 'eval_steps_per_second': 2.28, 'epoch': 4.89, 'step': 650}, {'train_runtime': 969.3891, 'train_samples_per_second': 21.849, 'train_steps_per_second': 0.686, 'total_flos': 2448958969107000.0, 'train_loss': 0.7719179691228651, 'epoch': 5.0, 'step': 665}]Confusion Matrix
[[103  42  39]
 [ 76 214  71]
 [ 32  42  94]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.49      0.56      0.52       184
     Neutral       0.72      0.59      0.65       361
     Counter       0.46      0.56      0.51       168

    accuracy                           0.58       713
   macro avg       0.56      0.57      0.56       713
weighted avg       0.60      0.58      0.58       713
{'eval_loss': 1.0210955142974854, 'eval_accuracy': 0.576437587657784, 'eval_precision': 0.5981392435587762, 'eval_recall': 0.576437587657784, 'eval_f1': 0.58249788160387, 'eval_runtime': 10.0221, 'eval_samples_per_second': 71.143, 'eval_steps_per_second': 2.295, 'epoch': 5.0}