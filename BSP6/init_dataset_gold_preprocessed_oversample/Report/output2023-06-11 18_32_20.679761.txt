modelroberta-basedataset: /content/drive/MyDrive/BSP6/init_dataset_gold_preprocessed_oversample
structure of the model: 
RobertaForSequenceClassification(
  (roberta): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (classifier): RobertaClassificationHead(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (out_proj): Linear(in_features=768, out_features=3, bias=True)
  )
)
Tokenizer max length train:225Tokenizer max length val:225Tokenizer max length test:225
TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=50,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=6.647881502185235e-06,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/runs/Jun11_18-32-35_39141246ffdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=4,
optim=adamw_hf,
optim_args=None,
output_dir=./results,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./results,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=17,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
Confusion Matrix
[[  0 331   0]
 [  0 356   0]
 [  0 249   0]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.00      0.00      0.00       331
     Neutral       0.38      1.00      0.55       356
     Counter       0.00      0.00      0.00       249

    accuracy                           0.38       936
   macro avg       0.13      0.33      0.18       936
weighted avg       0.14      0.38      0.21       936
Confusion Matrix
[[  0   3 328]
 [  0  16 340]
 [  0   5 244]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.00      0.00      0.00       331
     Neutral       0.67      0.04      0.08       356
     Counter       0.27      0.98      0.42       249

    accuracy                           0.28       936
   macro avg       0.31      0.34      0.17       936
weighted avg       0.32      0.28      0.14       936
Confusion Matrix
[[  0 331   0]
 [  0 356   0]
 [  0 249   0]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.00      0.00      0.00       331
     Neutral       0.38      1.00      0.55       356
     Counter       0.00      0.00      0.00       249

    accuracy                           0.38       936
   macro avg       0.13      0.33      0.18       936
weighted avg       0.14      0.38      0.21       936
Confusion Matrix
[[  0 307  24]
 [  0 350   6]
 [  0 231  18]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.00      0.00      0.00       331
     Neutral       0.39      0.98      0.56       356
     Counter       0.38      0.07      0.12       249

    accuracy                           0.39       936
   macro avg       0.26      0.35      0.23       936
weighted avg       0.25      0.39      0.25       936
Confusion Matrix
[[166 165   0]
 [101 255   0]
 [115 134   0]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.43      0.50      0.47       331
     Neutral       0.46      0.72      0.56       356
     Counter       0.00      0.00      0.00       249

    accuracy                           0.45       936
   macro avg       0.30      0.41      0.34       936
weighted avg       0.33      0.45      0.38       936
Confusion Matrix
[[237  94   0]
 [185 171   0]
 [183  66   0]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.39      0.72      0.51       331
     Neutral       0.52      0.48      0.50       356
     Counter       0.00      0.00      0.00       249

    accuracy                           0.44       936
   macro avg       0.30      0.40      0.33       936
weighted avg       0.34      0.44      0.37       936
Confusion Matrix
[[190 141   0]
 [102 252   2]
 [129 119   1]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.45      0.57      0.51       331
     Neutral       0.49      0.71      0.58       356
     Counter       0.33      0.00      0.01       249

    accuracy                           0.47       936
   macro avg       0.43      0.43      0.36       936
weighted avg       0.44      0.47      0.40       936
Confusion Matrix
[[184 147   0]
 [ 82 273   1]
 [117 130   2]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.48      0.56      0.52       331
     Neutral       0.50      0.77      0.60       356
     Counter       0.67      0.01      0.02       249

    accuracy                           0.49       936
   macro avg       0.55      0.44      0.38       936
weighted avg       0.54      0.49      0.42       936
Confusion Matrix
[[226  94  11]
 [112 232  12]
 [127 106  16]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.49      0.68      0.57       331
     Neutral       0.54      0.65      0.59       356
     Counter       0.41      0.06      0.11       249

    accuracy                           0.51       936
   macro avg       0.48      0.47      0.42       936
weighted avg       0.49      0.51      0.45       936
Confusion Matrix
[[119 194  18]
 [ 32 311  13]
 [ 43 181  25]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.61      0.36      0.45       331
     Neutral       0.45      0.87      0.60       356
     Counter       0.45      0.10      0.16       249

    accuracy                           0.49       936
   macro avg       0.50      0.44      0.40       936
weighted avg       0.51      0.49      0.43       936
Confusion Matrix
[[ 93 193  45]
 [ 24 320  12]
 [ 27 189  33]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.65      0.28      0.39       331
     Neutral       0.46      0.90      0.60       356
     Counter       0.37      0.13      0.19       249

    accuracy                           0.48       936
   macro avg       0.49      0.44      0.40       936
weighted avg       0.50      0.48      0.42       936
Confusion Matrix
[[168 111  52]
 [ 61 252  43]
 [ 73 128  48]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.56      0.51      0.53       331
     Neutral       0.51      0.71      0.60       356
     Counter       0.34      0.19      0.24       249

    accuracy                           0.50       936
   macro avg       0.47      0.47      0.46       936
weighted avg       0.48      0.50      0.48       936
Confusion Matrix
[[185 121  25]
 [ 59 273  24]
 [ 81 145  23]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.56      0.56       331
     Neutral       0.51      0.77      0.61       356
     Counter       0.32      0.09      0.14       249

    accuracy                           0.51       936
   macro avg       0.47      0.47      0.44       936
weighted avg       0.48      0.51      0.47       936
Confusion Matrix
[[199 100  32]
 [ 75 246  35]
 [ 78 126  45]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.60      0.58       331
     Neutral       0.52      0.69      0.59       356
     Counter       0.40      0.18      0.25       249

    accuracy                           0.52       936
   macro avg       0.50      0.49      0.48       936
weighted avg       0.51      0.52      0.50       936
Confusion Matrix
[[233  55  43]
 [ 96 191  69]
 [113  76  60]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.53      0.70      0.60       331
     Neutral       0.59      0.54      0.56       356
     Counter       0.35      0.24      0.29       249

    accuracy                           0.52       936
   macro avg       0.49      0.49      0.48       936
weighted avg       0.50      0.52      0.50       936
Confusion Matrix
[[190 101  40]
 [ 59 258  39]
 [ 75 118  56]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.57      0.58       331
     Neutral       0.54      0.72      0.62       356
     Counter       0.41      0.22      0.29       249

    accuracy                           0.54       936
   macro avg       0.51      0.51      0.50       936
weighted avg       0.52      0.54      0.52       936
Confusion Matrix
[[151 137  43]
 [ 39 289  28]
 [ 45 153  51]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.64      0.46      0.53       331
     Neutral       0.50      0.81      0.62       356
     Counter       0.42      0.20      0.27       249

    accuracy                           0.52       936
   macro avg       0.52      0.49      0.48       936
weighted avg       0.53      0.52      0.50       936
Confusion Matrix
[[235  52  44]
 [ 93 205  58]
 [104  74  71]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.54      0.71      0.62       331
     Neutral       0.62      0.58      0.60       356
     Counter       0.41      0.29      0.34       249

    accuracy                           0.55       936
   macro avg       0.52      0.52      0.52       936
weighted avg       0.54      0.55      0.53       936
Confusion Matrix
[[220  42  69]
 [ 84 185  87]
 [ 92  57 100]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.56      0.66      0.61       331
     Neutral       0.65      0.52      0.58       356
     Counter       0.39      0.40      0.40       249

    accuracy                           0.54       936
   macro avg       0.53      0.53      0.53       936
weighted avg       0.55      0.54      0.54       936
Confusion Matrix
[[164  67 100]
 [ 52 226  78]
 [ 54  86 109]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.61      0.50      0.55       331
     Neutral       0.60      0.63      0.61       356
     Counter       0.38      0.44      0.41       249

    accuracy                           0.53       936
   macro avg       0.53      0.52      0.52       936
weighted avg       0.54      0.53      0.54       936
Confusion Matrix
[[173 120  38]
 [ 51 280  25]
 [ 60 139  50]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.61      0.52      0.56       331
     Neutral       0.52      0.79      0.63       356
     Counter       0.44      0.20      0.28       249

    accuracy                           0.54       936
   macro avg       0.52      0.50      0.49       936
weighted avg       0.53      0.54      0.51       936
Confusion Matrix
[[240  36  55]
 [105 162  89]
 [102  44 103]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.54      0.73      0.62       331
     Neutral       0.67      0.46      0.54       356
     Counter       0.42      0.41      0.42       249

    accuracy                           0.54       936
   macro avg       0.54      0.53      0.52       936
weighted avg       0.56      0.54      0.53       936
Confusion Matrix
[[189  80  62]
 [ 66 242  48]
 [ 67 107  75]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.57      0.58       331
     Neutral       0.56      0.68      0.62       356
     Counter       0.41      0.30      0.35       249

    accuracy                           0.54       936
   macro avg       0.52      0.52      0.51       936
weighted avg       0.53      0.54      0.53       936
Confusion Matrix
[[178 105  48]
 [ 56 267  33]
 [ 60 128  61]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.61      0.54      0.57       331
     Neutral       0.53      0.75      0.62       356
     Counter       0.43      0.24      0.31       249

    accuracy                           0.54       936
   macro avg       0.52      0.51      0.50       936
weighted avg       0.53      0.54      0.52       936
Confusion Matrix
[[235  53  43]
 [ 91 203  62]
 [ 97  70  82]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.56      0.71      0.62       331
     Neutral       0.62      0.57      0.60       356
     Counter       0.44      0.33      0.38       249

    accuracy                           0.56       936
   macro avg       0.54      0.54      0.53       936
weighted avg       0.55      0.56      0.55       936
Confusion Matrix
[[226  44  61]
 [ 86 191  79]
 [ 94  56  99]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.56      0.68      0.61       331
     Neutral       0.66      0.54      0.59       356
     Counter       0.41      0.40      0.41       249

    accuracy                           0.55       936
   macro avg       0.54      0.54      0.54       936
weighted avg       0.56      0.55      0.55       936
Confusion Matrix
[[226  68  37]
 [ 86 222  48]
 [ 96  82  71]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.68      0.61       331
     Neutral       0.60      0.62      0.61       356
     Counter       0.46      0.29      0.35       249

    accuracy                           0.55       936
   macro avg       0.54      0.53      0.52       936
weighted avg       0.54      0.55      0.54       936
Confusion Matrix
[[222  53  56]
 [ 81 206  69]
 [ 89  63  97]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.67      0.61       331
     Neutral       0.64      0.58      0.61       356
     Counter       0.44      0.39      0.41       249

    accuracy                           0.56       936
   macro avg       0.55      0.55      0.54       936
weighted avg       0.56      0.56      0.56       936
Confusion Matrix
[[222  56  53]
 [ 78 213  65]
 [ 89  72  88]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.67      0.62       331
     Neutral       0.62      0.60      0.61       356
     Counter       0.43      0.35      0.39       249

    accuracy                           0.56       936
   macro avg       0.54      0.54      0.54       936
weighted avg       0.55      0.56      0.55       936
Confusion Matrix
[[224  58  49]
 [ 80 216  60]
 [ 89  78  82]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.68      0.62       331
     Neutral       0.61      0.61      0.61       356
     Counter       0.43      0.33      0.37       249

    accuracy                           0.56       936
   macro avg       0.54      0.54      0.53       936
weighted avg       0.55      0.56      0.55       936
Confusion Matrix
[[215  46  70]
 [ 79 194  83]
 [ 83  59 107]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.57      0.65      0.61       331
     Neutral       0.65      0.54      0.59       356
     Counter       0.41      0.43      0.42       249

    accuracy                           0.55       936
   macro avg       0.54      0.54      0.54       936
weighted avg       0.56      0.55      0.55       936
Confusion Matrix
[[243  48  40]
 [ 99 200  57]
 [105  67  77]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.54      0.73      0.62       331
     Neutral       0.63      0.56      0.60       356
     Counter       0.44      0.31      0.36       249

    accuracy                           0.56       936
   macro avg       0.54      0.54      0.53       936
weighted avg       0.55      0.56      0.54       936
Confusion Matrix
[[234  50  47]
 [ 90 201  65]
 [ 97  65  87]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.56      0.71      0.62       331
     Neutral       0.64      0.56      0.60       356
     Counter       0.44      0.35      0.39       249

    accuracy                           0.56       936
   macro avg       0.54      0.54      0.54       936
weighted avg       0.55      0.56      0.55       936
Confusion Matrix
[[217  50  64]
 [ 72 199  85]
 [ 77  62 110]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.66      0.62       331
     Neutral       0.64      0.56      0.60       356
     Counter       0.42      0.44      0.43       249

    accuracy                           0.56       936
   macro avg       0.55      0.55      0.55       936
weighted avg       0.57      0.56      0.56       936
Confusion Matrix
[[196  66  69]
 [ 66 217  73]
 [ 66  78 105]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.60      0.59      0.59       331
     Neutral       0.60      0.61      0.61       356
     Counter       0.43      0.42      0.42       249

    accuracy                           0.55       936
   macro avg       0.54      0.54      0.54       936
weighted avg       0.55      0.55      0.55       936
Confusion Matrix
[[232  58  41]
 [ 90 211  55]
 [ 98  74  77]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.70      0.62       331
     Neutral       0.62      0.59      0.60       356
     Counter       0.45      0.31      0.36       249

    accuracy                           0.56       936
   macro avg       0.54      0.53      0.53       936
weighted avg       0.55      0.56      0.55       936
Confusion Matrix
[[236  51  44]
 [ 96 197  63]
 [ 98  70  81]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.71      0.62       331
     Neutral       0.62      0.55      0.58       356
     Counter       0.43      0.33      0.37       249

    accuracy                           0.55       936
   macro avg       0.53      0.53      0.53       936
weighted avg       0.54      0.55      0.54       936
Confusion Matrix
[[200  69  62]
 [ 64 222  70]
 [ 66  79 104]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.61      0.60      0.61       331
     Neutral       0.60      0.62      0.61       356
     Counter       0.44      0.42      0.43       249

    accuracy                           0.56       936
   macro avg       0.55      0.55      0.55       936
weighted avg       0.56      0.56      0.56       936
Confusion Matrix
[[212  53  66]
 [ 71 201  84]
 [ 75  64 110]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.59      0.64      0.62       331
     Neutral       0.63      0.56      0.60       356
     Counter       0.42      0.44      0.43       249

    accuracy                           0.56       936
   macro avg       0.55      0.55      0.55       936
weighted avg       0.56      0.56      0.56       936
Confusion Matrix
[[202  67  62]
 [ 64 217  75]
 [ 70  74 105]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.60      0.61      0.61       331
     Neutral       0.61      0.61      0.61       356
     Counter       0.43      0.42      0.43       249

    accuracy                           0.56       936
   macro avg       0.55      0.55      0.55       936
weighted avg       0.56      0.56      0.56       936
Confusion Matrix
[[196  63  72]
 [ 65 211  80]
 [ 61  72 116]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.61      0.59      0.60       331
     Neutral       0.61      0.59      0.60       356
     Counter       0.43      0.47      0.45       249

    accuracy                           0.56       936
   macro avg       0.55      0.55      0.55       936
weighted avg       0.56      0.56      0.56       936
Confusion Matrix
[[203  65  63]
 [ 66 211  79]
 [ 71  72 106]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.60      0.61      0.61       331
     Neutral       0.61      0.59      0.60       356
     Counter       0.43      0.43      0.43       249

    accuracy                           0.56       936
   macro avg       0.54      0.54      0.54       936
weighted avg       0.56      0.56      0.56       936
[{'loss': 1.1117, 'learning_rate': 6.491091844114828e-06, 'epoch': 0.09, 'step': 50}, {'eval_loss': 1.1012132167816162, 'eval_accuracy': 0.3803418803418803, 'eval_precision': 0.14465994594199721, 'eval_recall': 0.3803418803418803, 'eval_f1': 0.20960016935249134, 'eval_runtime': 4.0849, 'eval_samples_per_second': 229.136, 'eval_steps_per_second': 28.642, 'epoch': 0.09, 'step': 50}, {'loss': 1.1032, 'learning_rate': 6.3343021860444215e-06, 'epoch': 0.19, 'step': 100}, {'eval_loss': 1.1015019416809082, 'eval_accuracy': 0.2777777777777778, 'eval_precision': 0.3247347803268856, 'eval_recall': 0.2777777777777778, 'eval_f1': 0.1438466304235378, 'eval_runtime': 4.0431, 'eval_samples_per_second': 231.505, 'eval_steps_per_second': 28.938, 'epoch': 0.19, 'step': 100}, {'loss': 1.0964, 'learning_rate': 6.177512527974015e-06, 'epoch': 0.28, 'step': 150}, {'eval_loss': 1.091752529144287, 'eval_accuracy': 0.3803418803418803, 'eval_precision': 0.14465994594199721, 'eval_recall': 0.3803418803418803, 'eval_f1': 0.20960016935249134, 'eval_runtime': 4.3862, 'eval_samples_per_second': 213.396, 'eval_steps_per_second': 26.674, 'epoch': 0.28, 'step': 150}, {'loss': 1.0943, 'learning_rate': 6.0207228699036085e-06, 'epoch': 0.38, 'step': 200}, {'eval_loss': 1.0919606685638428, 'eval_accuracy': 0.39316239316239315, 'eval_precision': 0.2496691402941403, 'eval_recall': 0.39316239316239315, 'eval_f1': 0.246264275203182, 'eval_runtime': 4.0554, 'eval_samples_per_second': 230.804, 'eval_steps_per_second': 28.851, 'epoch': 0.38, 'step': 200}, {'loss': 1.0678, 'learning_rate': 5.863933211833202e-06, 'epoch': 0.47, 'step': 250}, {'eval_loss': 1.0713586807250977, 'eval_accuracy': 0.4497863247863248, 'eval_precision': 0.32873986348243067, 'eval_recall': 0.4497863247863248, 'eval_f1': 0.3778234088947219, 'eval_runtime': 4.08, 'eval_samples_per_second': 229.411, 'eval_steps_per_second': 28.676, 'epoch': 0.47, 'step': 250}, {'loss': 1.0411, 'learning_rate': 5.707143553762796e-06, 'epoch': 0.57, 'step': 300}, {'eval_loss': 1.056071400642395, 'eval_accuracy': 0.4358974358974359, 'eval_precision': 0.3350212293428443, 'eval_recall': 0.4358974358974359, 'eval_f1': 0.36842361356343545, 'eval_runtime': 4.2126, 'eval_samples_per_second': 222.189, 'eval_steps_per_second': 27.774, 'epoch': 0.57, 'step': 300}, {'loss': 1.0586, 'learning_rate': 5.550353895692389e-06, 'epoch': 0.66, 'step': 350}, {'eval_loss': 1.042715311050415, 'eval_accuracy': 0.4732905982905983, 'eval_precision': 0.4354713384645837, 'eval_recall': 0.4732905982905983, 'eval_f1': 0.40165225020664286, 'eval_runtime': 4.0705, 'eval_samples_per_second': 229.946, 'eval_steps_per_second': 28.743, 'epoch': 0.66, 'step': 350}, {'loss': 1.0666, 'learning_rate': 5.393564237621983e-06, 'epoch': 0.75, 'step': 400}, {'eval_loss': 1.029232144355774, 'eval_accuracy': 0.49038461538461536, 'eval_precision': 0.5360296274656587, 'eval_recall': 0.49038461538461536, 'eval_f1': 0.4156996443225504, 'eval_runtime': 4.0726, 'eval_samples_per_second': 229.829, 'eval_steps_per_second': 28.729, 'epoch': 0.75, 'step': 400}, {'loss': 1.0285, 'learning_rate': 5.236774579551577e-06, 'epoch': 0.85, 'step': 450}, {'eval_loss': 1.0104196071624756, 'eval_accuracy': 0.5064102564102564, 'eval_precision': 0.4852693906181637, 'eval_recall': 0.5064102564102564, 'eval_f1': 0.45432244232718694, 'eval_runtime': 4.2048, 'eval_samples_per_second': 222.601, 'eval_steps_per_second': 27.825, 'epoch': 0.85, 'step': 450}, {'loss': 1.0143, 'learning_rate': 5.07998492148117e-06, 'epoch': 0.94, 'step': 500}, {'eval_loss': 1.0819648504257202, 'eval_accuracy': 0.4861111111111111, 'eval_precision': 0.5081093832967649, 'eval_recall': 0.4861111111111111, 'eval_f1': 0.4309612428576589, 'eval_runtime': 4.0707, 'eval_samples_per_second': 229.936, 'eval_steps_per_second': 28.742, 'epoch': 0.94, 'step': 500}, {'loss': 1.0395, 'learning_rate': 4.9231952634107636e-06, 'epoch': 1.04, 'step': 550}, {'eval_loss': 1.08579683303833, 'eval_accuracy': 0.47649572649572647, 'eval_precision': 0.49930559360313637, 'eval_recall': 0.47649572649572647, 'eval_f1': 0.420342119798362, 'eval_runtime': 4.392, 'eval_samples_per_second': 213.116, 'eval_steps_per_second': 26.64, 'epoch': 1.04, 'step': 550}, {'loss': 0.9767, 'learning_rate': 4.766405605340356e-06, 'epoch': 1.13, 'step': 600}, {'eval_loss': 1.0149753093719482, 'eval_accuracy': 0.5, 'eval_precision': 0.4812240393897175, 'eval_recall': 0.5, 'eval_f1': 0.47917840282584545, 'eval_runtime': 4.1855, 'eval_samples_per_second': 223.63, 'eval_steps_per_second': 27.954, 'epoch': 1.13, 'step': 600}, {'loss': 0.9928, 'learning_rate': 4.6096159472699505e-06, 'epoch': 1.23, 'step': 650}, {'eval_loss': 1.000584363937378, 'eval_accuracy': 0.5138888888888888, 'eval_precision': 0.478919593583055, 'eval_recall': 0.5138888888888888, 'eval_f1': 0.46960919276660507, 'eval_runtime': 4.2066, 'eval_samples_per_second': 222.505, 'eval_steps_per_second': 27.813, 'epoch': 1.23, 'step': 650}, {'loss': 0.9251, 'learning_rate': 4.452826289199544e-06, 'epoch': 1.32, 'step': 700}, {'eval_loss': 1.006999135017395, 'eval_accuracy': 0.5235042735042735, 'eval_precision': 0.5050372400081087, 'eval_recall': 0.5235042735042735, 'eval_f1': 0.49839230745151436, 'eval_runtime': 4.0545, 'eval_samples_per_second': 230.854, 'eval_steps_per_second': 28.857, 'epoch': 1.32, 'step': 700}, {'loss': 0.9459, 'learning_rate': 4.296036631129137e-06, 'epoch': 1.42, 'step': 750}, {'eval_loss': 0.9872204661369324, 'eval_accuracy': 0.5170940170940171, 'eval_precision': 0.5048232823920935, 'eval_recall': 0.5170940170940171, 'eval_f1': 0.5033056483011626, 'eval_runtime': 4.0714, 'eval_samples_per_second': 229.896, 'eval_steps_per_second': 28.737, 'epoch': 1.42, 'step': 750}, {'loss': 0.9728, 'learning_rate': 4.139246973058731e-06, 'epoch': 1.51, 'step': 800}, {'eval_loss': 0.9772939682006836, 'eval_accuracy': 0.5384615384615384, 'eval_precision': 0.5234479554273406, 'eval_recall': 0.5384615384615384, 'eval_f1': 0.5183535723449685, 'eval_runtime': 4.2469, 'eval_samples_per_second': 220.398, 'eval_steps_per_second': 27.55, 'epoch': 1.51, 'step': 800}, {'loss': 0.9286, 'learning_rate': 3.982457314988324e-06, 'epoch': 1.6, 'step': 850}, {'eval_loss': 1.011716365814209, 'eval_accuracy': 0.5245726495726496, 'eval_precision': 0.5282776108117767, 'eval_recall': 0.5245726495726496, 'eval_f1': 0.49694685439901787, 'eval_runtime': 4.0631, 'eval_samples_per_second': 230.367, 'eval_steps_per_second': 28.796, 'epoch': 1.6, 'step': 850}, {'loss': 0.933, 'learning_rate': 3.825667656917918e-06, 'epoch': 1.7, 'step': 900}, {'eval_loss': 0.9882084727287292, 'eval_accuracy': 0.5459401709401709, 'eval_precision': 0.5371068434842496, 'eval_recall': 0.5459401709401709, 'eval_f1': 0.5343367844386732, 'eval_runtime': 4.0679, 'eval_samples_per_second': 230.097, 'eval_steps_per_second': 28.762, 'epoch': 1.7, 'step': 900}, {'loss': 0.9278, 'learning_rate': 3.6688779988475117e-06, 'epoch': 1.79, 'step': 950}, {'eval_loss': 0.9991775751113892, 'eval_accuracy': 0.5395299145299145, 'eval_precision': 0.5481366691662319, 'eval_recall': 0.5395299145299145, 'eval_f1': 0.5392697491266691, 'eval_runtime': 5.2081, 'eval_samples_per_second': 179.718, 'eval_steps_per_second': 22.465, 'epoch': 1.79, 'step': 950}, {'loss': 0.935, 'learning_rate': 3.512088340777105e-06, 'epoch': 1.89, 'step': 1000}, {'eval_loss': 0.976392388343811, 'eval_accuracy': 0.5331196581196581, 'eval_precision': 0.5426332868855624, 'eval_recall': 0.5331196581196581, 'eval_f1': 0.5350917413444021, 'eval_runtime': 4.0721, 'eval_samples_per_second': 229.859, 'eval_steps_per_second': 28.732, 'epoch': 1.89, 'step': 1000}, {'loss': 0.9608, 'learning_rate': 3.355298682706699e-06, 'epoch': 1.98, 'step': 1050}, {'eval_loss': 0.973046064376831, 'eval_accuracy': 0.5373931623931624, 'eval_precision': 0.530707625828684, 'eval_recall': 0.5373931623931624, 'eval_f1': 0.5104212307158951, 'eval_runtime': 4.1805, 'eval_samples_per_second': 223.896, 'eval_steps_per_second': 27.987, 'epoch': 1.98, 'step': 1050}, {'loss': 0.8622, 'learning_rate': 3.198509024636292e-06, 'epoch': 2.08, 'step': 1100}, {'eval_loss': 1.0207033157348633, 'eval_accuracy': 0.5395299145299145, 'eval_precision': 0.5554125838561026, 'eval_recall': 0.5395299145299145, 'eval_f1': 0.5347373974655981, 'eval_runtime': 4.1517, 'eval_samples_per_second': 225.449, 'eval_steps_per_second': 28.181, 'epoch': 2.08, 'step': 1100}, {'loss': 0.8336, 'learning_rate': 3.0417193665658855e-06, 'epoch': 2.17, 'step': 1150}, {'eval_loss': 0.995051920413971, 'eval_accuracy': 0.5405982905982906, 'eval_precision': 0.5299669524167852, 'eval_recall': 0.5405982905982906, 'eval_f1': 0.5311542197593946, 'eval_runtime': 4.2063, 'eval_samples_per_second': 222.521, 'eval_steps_per_second': 27.815, 'epoch': 2.17, 'step': 1150}, {'loss': 0.8713, 'learning_rate': 2.8849297084954794e-06, 'epoch': 2.26, 'step': 1200}, {'eval_loss': 1.0094494819641113, 'eval_accuracy': 0.5405982905982906, 'eval_precision': 0.5314852022186026, 'eval_recall': 0.5405982905982906, 'eval_f1': 0.521703853396035, 'eval_runtime': 4.9932, 'eval_samples_per_second': 187.454, 'eval_steps_per_second': 23.432, 'epoch': 2.26, 'step': 1200}, {'loss': 0.8219, 'learning_rate': 2.728140050425073e-06, 'epoch': 2.36, 'step': 1250}, {'eval_loss': 0.9980629086494446, 'eval_accuracy': 0.5555555555555556, 'eval_precision': 0.5499540985677157, 'eval_recall': 0.5555555555555556, 'eval_f1': 0.5469192619380274, 'eval_runtime': 4.4552, 'eval_samples_per_second': 210.093, 'eval_steps_per_second': 26.262, 'epoch': 2.36, 'step': 1250}, {'loss': 0.8916, 'learning_rate': 2.5713503923546664e-06, 'epoch': 2.45, 'step': 1300}, {'eval_loss': 1.0092171430587769, 'eval_accuracy': 0.5512820512820513, 'eval_precision': 0.5566845311772108, 'eval_recall': 0.5512820512820513, 'eval_f1': 0.5493788546723216, 'eval_runtime': 4.2037, 'eval_samples_per_second': 222.659, 'eval_steps_per_second': 27.832, 'epoch': 2.45, 'step': 1300}, {'loss': 0.7806, 'learning_rate': 2.4145607342842594e-06, 'epoch': 2.55, 'step': 1350}, {'eval_loss': 1.003807783126831, 'eval_accuracy': 0.5544871794871795, 'eval_precision': 0.5439386487134992, 'eval_recall': 0.5544871794871795, 'eval_f1': 0.5415347702302816, 'eval_runtime': 4.1145, 'eval_samples_per_second': 227.488, 'eval_steps_per_second': 28.436, 'epoch': 2.55, 'step': 1350}, {'loss': 0.8175, 'learning_rate': 2.2577710762138533e-06, 'epoch': 2.64, 'step': 1400}, {'eval_loss': 1.0171968936920166, 'eval_accuracy': 0.5608974358974359, 'eval_precision': 0.559832192013869, 'eval_recall': 0.5608974358974359, 'eval_f1': 0.5578638916437334, 'eval_runtime': 4.4767, 'eval_samples_per_second': 209.082, 'eval_steps_per_second': 26.135, 'epoch': 2.64, 'step': 1400}, {'loss': 0.9076, 'learning_rate': 2.1009814181434467e-06, 'epoch': 2.74, 'step': 1450}, {'eval_loss': 0.9862045049667358, 'eval_accuracy': 0.5587606837606838, 'eval_precision': 0.5530322397817328, 'eval_recall': 0.5587606837606838, 'eval_f1': 0.553437052688653, 'eval_runtime': 4.2416, 'eval_samples_per_second': 220.672, 'eval_steps_per_second': 27.584, 'epoch': 2.74, 'step': 1450}, {'loss': 0.8512, 'learning_rate': 1.94419176007304e-06, 'epoch': 2.83, 'step': 1500}, {'eval_loss': 0.9774685502052307, 'eval_accuracy': 0.5576923076923077, 'eval_precision': 0.549163083998822, 'eval_recall': 0.5576923076923077, 'eval_f1': 0.5500503306091377, 'eval_runtime': 4.1346, 'eval_samples_per_second': 226.384, 'eval_steps_per_second': 28.298, 'epoch': 2.83, 'step': 1500}, {'loss': 0.8537, 'learning_rate': 1.7874021020026339e-06, 'epoch': 2.92, 'step': 1550}, {'eval_loss': 0.9952452778816223, 'eval_accuracy': 0.5512820512820513, 'eval_precision': 0.5579304837226357, 'eval_recall': 0.5512820512820513, 'eval_f1': 0.5519242937865418, 'eval_runtime': 4.1542, 'eval_samples_per_second': 225.314, 'eval_steps_per_second': 28.164, 'epoch': 2.92, 'step': 1550}, {'loss': 0.818, 'learning_rate': 1.6306124439322273e-06, 'epoch': 3.02, 'step': 1600}, {'eval_loss': 1.0049649477005005, 'eval_accuracy': 0.5555555555555556, 'eval_precision': 0.5514540582474318, 'eval_recall': 0.5555555555555556, 'eval_f1': 0.5444889808980387, 'eval_runtime': 4.0967, 'eval_samples_per_second': 228.479, 'eval_steps_per_second': 28.56, 'epoch': 3.02, 'step': 1600}, {'loss': 0.7744, 'learning_rate': 1.473822785861821e-06, 'epoch': 3.11, 'step': 1650}, {'eval_loss': 1.012288212776184, 'eval_accuracy': 0.5576923076923077, 'eval_precision': 0.554784809282024, 'eval_recall': 0.5576923076923077, 'eval_f1': 0.5509281923011976, 'eval_runtime': 4.2328, 'eval_samples_per_second': 221.132, 'eval_steps_per_second': 27.641, 'epoch': 3.11, 'step': 1650}, {'loss': 0.8429, 'learning_rate': 1.3170331277914145e-06, 'epoch': 3.21, 'step': 1700}, {'eval_loss': 1.0105797052383423, 'eval_accuracy': 0.561965811965812, 'eval_precision': 0.5660210917215028, 'eval_recall': 0.561965811965812, 'eval_f1': 0.5623544152054125, 'eval_runtime': 4.1019, 'eval_samples_per_second': 228.186, 'eval_steps_per_second': 28.523, 'epoch': 3.21, 'step': 1700}, {'loss': 0.7926, 'learning_rate': 1.160243469721008e-06, 'epoch': 3.3, 'step': 1750}, {'eval_loss': 0.999761700630188, 'eval_accuracy': 0.5534188034188035, 'eval_precision': 0.5530313516984766, 'eval_recall': 0.5534188034188035, 'eval_f1': 0.5532076906484686, 'eval_runtime': 4.1137, 'eval_samples_per_second': 227.533, 'eval_steps_per_second': 28.442, 'epoch': 3.3, 'step': 1750}, {'loss': 0.7389, 'learning_rate': 1.0034538116506014e-06, 'epoch': 3.4, 'step': 1800}, {'eval_loss': 1.0124287605285645, 'eval_accuracy': 0.5555555555555556, 'eval_precision': 0.5477155655786068, 'eval_recall': 0.5555555555555556, 'eval_f1': 0.5451896025482178, 'eval_runtime': 4.9848, 'eval_samples_per_second': 187.77, 'eval_steps_per_second': 23.471, 'epoch': 3.4, 'step': 1800}, {'loss': 0.7653, 'learning_rate': 8.46664153580195e-07, 'epoch': 3.49, 'step': 1850}, {'eval_loss': 1.021920919418335, 'eval_accuracy': 0.5491452991452992, 'eval_precision': 0.5443246919613584, 'eval_recall': 0.5491452991452992, 'eval_f1': 0.5402903341910701, 'eval_runtime': 5.3108, 'eval_samples_per_second': 176.245, 'eval_steps_per_second': 22.031, 'epoch': 3.49, 'step': 1850}, {'loss': 0.7568, 'learning_rate': 6.898744955097885e-07, 'epoch': 3.58, 'step': 1900}, {'eval_loss': 1.016287088394165, 'eval_accuracy': 0.561965811965812, 'eval_precision': 0.5597594809459217, 'eval_recall': 0.561965811965812, 'eval_f1': 0.5606935993496358, 'eval_runtime': 4.0874, 'eval_samples_per_second': 228.998, 'eval_steps_per_second': 28.625, 'epoch': 3.58, 'step': 1900}, {'loss': 0.7883, 'learning_rate': 5.33084837439382e-07, 'epoch': 3.68, 'step': 1950}, {'eval_loss': 1.0207855701446533, 'eval_accuracy': 0.5587606837606838, 'eval_precision': 0.5623677296528201, 'eval_recall': 0.5587606837606838, 'eval_f1': 0.5594523949677858, 'eval_runtime': 4.4156, 'eval_samples_per_second': 211.978, 'eval_steps_per_second': 26.497, 'epoch': 3.68, 'step': 1950}, {'loss': 0.74, 'learning_rate': 3.7629517936897553e-07, 'epoch': 3.77, 'step': 2000}, {'eval_loss': 1.0172662734985352, 'eval_accuracy': 0.5598290598290598, 'eval_precision': 0.5585672512808749, 'eval_recall': 0.5598290598290598, 'eval_f1': 0.5591611741392818, 'eval_runtime': 4.071, 'eval_samples_per_second': 229.918, 'eval_steps_per_second': 28.74, 'epoch': 3.77, 'step': 2000}, {'loss': 0.8135, 'learning_rate': 2.1950552129856907e-07, 'epoch': 3.87, 'step': 2050}, {'eval_loss': 1.021913766860962, 'eval_accuracy': 0.5587606837606838, 'eval_precision': 0.5623425706928462, 'eval_recall': 0.5587606837606838, 'eval_f1': 0.5603034403494294, 'eval_runtime': 4.2182, 'eval_samples_per_second': 221.896, 'eval_steps_per_second': 27.737, 'epoch': 3.87, 'step': 2050}, {'loss': 0.717, 'learning_rate': 6.271586322816259e-08, 'epoch': 3.96, 'step': 2100}, {'eval_loss': 1.0203361511230469, 'eval_accuracy': 0.5555555555555556, 'eval_precision': 0.5554534878800402, 'eval_recall': 0.5555555555555556, 'eval_f1': 0.5554361166265172, 'eval_runtime': 4.074, 'eval_samples_per_second': 229.75, 'eval_steps_per_second': 28.719, 'epoch': 3.96, 'step': 2100}, {'train_runtime': 489.3797, 'train_samples_per_second': 34.623, 'train_steps_per_second': 4.332, 'total_flos': 1959167175285600.0, 'train_loss': 0.9097119115433603, 'epoch': 4.0, 'step': 2120}]Confusion Matrix
[[ 91  37  56]
 [ 49 238  74]
 [ 24  56  88]]
Classification Report
              precision    recall  f1-score   support

        Hate       0.55      0.49      0.52       184
     Neutral       0.72      0.66      0.69       361
     Counter       0.40      0.52      0.46       168

    accuracy                           0.58       713
   macro avg       0.56      0.56      0.56       713
weighted avg       0.60      0.58      0.59       713
{'eval_loss': 0.9304680228233337, 'eval_accuracy': 0.5848527349228612, 'eval_precision': 0.602363354440294, 'eval_recall': 0.5848527349228612, 'eval_f1': 0.5906715854166141, 'eval_runtime': 3.1522, 'eval_samples_per_second': 226.19, 'eval_steps_per_second': 28.551, 'epoch': 4.0}